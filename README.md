# Faster_RCNN With Comment
</br>

### Important Components:
1. The input layer is only useful during training. Each time you take a batch of pictures from an epoch picture according to the configuration, the shortest side is scaled to 600 pixels. Each time an epoch is completed, the shuffle picture is sorted.
2. The CNN layer receives the resize picture, and after convolution and pooling, the size is not changed after each convolution by adding a pad, and it is halved after pooling. Finally, the feature map is proportional to the input map and is reused by the RPN (Region Proposal Network) and the ROI layer.
    + There are total of 4 pooling, the number of channels of the final convolution output is 512 (VGG16), the corresponding ratio of the feature map size and the input zoom map mapping is 1/16, the final output of the volume base layer is 'conv5_3', and the input is sent to RPN to calculate The corresponding box is sent all the way to the ROI to calculate the corresponding feature map for classification.

3. RPN layer (Region Proposal Network), the input is a feature map n × n sliding window (n = 3 in the paper), and the output is the score of a set of boxes and corresponding boxes. A sliding window corresponding to the VGG16 network structure can cover a 228 pixel area Auxiliary upper anchor (Anchor), which can be translated into 9 regions. This layer removes 2 losses and sends the frame to the ROI layer.
    + The model is responsible for generating the 'box' network.The input is a sliding window n × n in the feature map in CNN, and the output is the frame and the corresponding score for the object. The effective coverage of a sliding window is 228x228. After mapping (the default scale and radio are both [0.5: 1, 1: 1, 2: 1]) into 9 boxes
    + "The design of multiscale anchors is a key component for sharing features without extra cost for addressing scales."
    + RPN receives a 512xHxW feature map. After one convolution, it throws out 2 channels, all of which are used to generate K boxes (2 value cls, FG and BG scores), and the corresponding scores are generated all the way (4 value bbox identifies rectangular boxes) .The network The structure is as follows:
    `layer {
  name: "rpn_conv/3x3"
  type: "Convolution"
  bottom: "conv5_3"
  top: "rpn/output"
  param { lr_mult: 1.0 }
  param { lr_mult: 2.0 }
  convolution_param {
    num_output: 512
    kernel_size: 3 pad: 1 stride: 1
    weight_filler { type: "gaussian" std: 0.01 }
    bias_filler { type: "constant" value: 0 }
  }
}
layer {
  name: "rpn_relu/3x3"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}`
    + Then all the anchor scores of the graph are sent to calculate the loss to calculate the softmax probability of FG and BG. The output of 'rpn_cls_prob' is (1,2, 9 * h_conv, w_conv), and then reshape back to (1,18, h_conv, w_conv The probability of the 9 anchors of each window came out, combined with the corresponding box and sent to the proposal layer; the other output of 'rpn_conv / 3x3' was sent to 'rpn_bbox_pred' to calculate the corresponding box (1,36, h_conv, w_conv) , 'rpn_bbox_pred' calculates the loss of the box all the way and sends it to the proposal layer; the probability of the input of the proposal layer set and the proposal generated by the box are sent to the ROI layer. 
    + RPN loss contains two parts: the loss of score and the loss of bbox.</br>
L ((pi, ti)) = 1 / Ncls × ΣLcls (pi, pi) + λ × 1 / Lreg × Σpi × Lreg (ti, ti), where i is the serial number of the anchor in the mini-batch, and pi is the i-th Anchor prediction is the probability of the object, pi = 1 if ith anchor is ground true else 0.ti is the rectangular 4 value in the positive example of prediction. Lcls is the log loss of 2 values, Lreg (ti, ti) = R (ti, ti) where R stands for RobustLoss, and λ is a parameter used to balance two losses by default is 10.</br>As the paper states, 'This can be thought of as bounding-box regression from an anchor box to a nearby ground-truth box.' Corresponding box. The original box based on different size ratios and aspect ratios and the regressors are convolved to get a box with k (9) approximate ground true.
    + Most anchor images in the pictures are counterexamples, causing data imbalance, and there are too many anchors around 20k. Random 128 positive anchors and 128 counter examples. If the number of positive examples is not enough, 128 counterfills are used. In the paper and in the code, use The training is one image at a time, and training is performed with SGD. The training can be RPN and RCNN alternately training iteratively, and it can also synthesize a large network to calculate its own loss. The author's experiments show that using the large network training has similar accuracy Down 1 ~ 1.5 times faster.
    
4. The ROI layer receives the input of the RPN and the input of the CNN to obtain the input of the feature map of the proposal and sends it to the classifier.

5. The classification layer receives the feature input of the ROI layer to give the classification result. This layer has two losses, one is the classification loss and the other is the box loss.


### Core Files:
1. CSI4106_Faster_RCNN/train.py Is the main caller
  + `train.train()` </br>
    + get the training set and load it.
  + `train = Train()` </br>
    + create a session
    + Create a network architecture
    + Load weights
    + Loop train step
                    ` rpn_loss_cls, rpn_loss_box, loss_cls, loss_box, total_loss = self.net.train_step(sess, blobs, train_op) `
  
------
2. CSI4106_Faster_RCNN/lib/nets/network.py Compute 4 losses
  + loss1: RPN's binary classification (it's an object or background)</br>` rpn_cross_entropy = tf.reduce_mean(
                tf.nn.sparse_softmax_cross_entropy_with_logits(logits=rpn_cls_score, labels=rpn_label))`
  + loss2: RPN's loss of regression (bbox)</br>` rpn_loss_box = self._smooth_l1_loss(rpn_bbox_pred, rpn_bbox_targets, rpn_bbox_inside_weights, rpn_bbox_outside_weights, sigma=sigma_rpn, dim=[1, 2, 3])`
  + loss3: fully connected network's softmax (20 classification)</br>`cross_entropy = tf.reduce_mean( tf.nn.sparse_softmax_cross_entropy_with_logits(logits=tf.reshape(cls_score, [-1, self._num_classes]), labels=label))`
  + loss4: fully connected network's regression (bbox)</br>`  loss_box = self._smooth_l1_loss(bbox_pred, bbox_targets, bbox_inside_weights, bbox_outside_weights)`
   `loss = cross_entropy + loss_box + rpn_cross_entropy + rpn_loss_box`

------

3. CSI4106_Faster_RCNN/lib/nets/vgg16.py Build 4 networks
  + __`build_head`: First net__</br>
     + 3x3 convolution layers would not change the size of feature map in vgg16</br>`rpn = slim.conv2d(net, 512, [3, 3], trainable=is_training, weights_initializer=initializer, scope="rpn_conv/3x3")`
     + 2x2 pooling change the size from 2x2 to 1x1, therefore, the number of pooling laber determine the size</br>
     + 5 conv2d layers and 4 pooling layers (0.5*0.5*0.5*0.5 = 1/16)</br>
     + It's not fully connected, therefore, the input of the model does not have  to resize to the same size since CNN can get any size of image 
  + __`build_rpn`: Second net__</br>
     + Input is the feature maps from vgg16</br>
     + In general, habe 3x3 convolution and get 256 feature maps, at this moment, there isn't any bound box.</br>
     + For each point in the feature map, there is an anchor which correspond a region of original input(16x larger(4 pooling layers  1/0.5^4 = 16))</br>
     + Therefore, for each point(anchor) on the feature map, correspoind 16 times of orginal image and find k anchor boxes.</br>
     + For a 3x3 region on conv feature map, we can find size of 1x1,2x1,1x2.(3 types) and 3 base size. Therefore, k is 3x3=9. (9 anchor boxes for a point in a conv feature map)</br>
     + In the paper, the writer says an 600*1000 image through conv layers and pooling layers can get 256 feature map with size about 40*60. </br>
     + In this way, we get a lot of boxes(about 2000 from the paper) for each feature map. We can use classification and regression to the boxes latter.</br>
     + Classification Layer(2*9=18 1x1 conv)</br>
     + For k(9) anchor boxes, do binary classfication(frontground or background)</br>
     + A conv layer with 1x1 and get 2k scores.</br>
     + Regression Layer(4*9=36 1x1 conv)</br>
     + For each box, there are x1,y1,x2,y2. We regression on these points to adjust the size,shape,position of boxes.</br>
     + Since there are k(9) anchor boxes for each point, we have 4(x1,y1,x2,y2)*k coordinates</br>
  
  + __`build_proposals`: Third net__</br>
     &nbsp; &nbsp; &nbsp; &nbsp; IOU = Intersation of Unit;
     NMS = Non-maximum suppression;
     bbox = boundary box
     + Background:
       + Input is the boxes that generated in RPN and feature map generated in vgg16.
       + At this moment, we map all boxes to original image.
       + Therefore, we can calculate IOU.
       + When IOU > a standard(0.7), it is an object.
       + Each bbox has a probility for an object, for each anchnor, we have 9 bbox with 9 probility(of objectiveness) in RPN layer.
     + Reduce bbox:
        + If we have 2000 boxes, it's a lot. We reduce the number of boxes and only keep boxes that are valuable. There are three methods to reduce the boxes
            1. IOU
                If IOU<0.7, we don't do regression. Stop.
            2. NMS
                If it's an object(>=0.7), IOU is large. There are many boxes around the same object. 
                Use NMS to keep only the boxes with high probility of it's an object.
            3. MAX
                If the boundary box is out of the image, ignore the bbox.
      + As a result, we reduce bbox from 2000 to 128(sort based on the probility of it's an object, and only take the highest 128 bbox)        
  + __`build_predictions`: Fourth net__</br>
      &nbsp; &nbsp; &nbsp; &nbsp; Here is a network that's fully connected net and fc6, fc7 with size of 4096.</br>&nbsp; &nbsp; &nbsp; &nbsp;`fc6 = slim.fully_connected(pool5_flat, 4096, scope='fc6')`</br>&nbsp; &nbsp; &nbsp; &nbsp;`fc7 = slim.fully_connected(fc6, 4096, scope='fc7')`</br>
      &nbsp; &nbsp; &nbsp; &nbsp; Use scores and predictions to do classfications and bbox regression.
      + Do Classfication 
        + cls_score is the result classification(21)</br> `cls_score = slim.fully_connected(fc7, self._num_classes, weights_initializer=initializer, trainable=is_training, activation_fn=None, scope='cls_score')`</br>
        + nput the classification score into the fully connected layer</br>`cls_prob = self._softmax_layer(cls_score, "cls_prob")`
      + Do bbox regression(21x4)
        + Already have target, proposal target layer.</br>` bbox_prediction = slim.fully_connected(fc7, self._num_classes * 4, weights_initializer=initializer_bbox, trainable=is_training, activation_fn=None, scope='bbox_pred')`


  
